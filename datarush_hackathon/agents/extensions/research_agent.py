"""
Research Agent Module
====================

Agente de investigaci√≥n que puede buscar informaci√≥n externa cuando no tiene
respuestas espec√≠ficas sobre los datos del sistema DataRush.

Capacidades:
- B√∫squeda web inteligente
- An√°lisis de contexto de datos
- Generaci√≥n de insights basados en investigaci√≥n
- Integraci√≥n con m√∫ltiples fuentes de informaci√≥n
"""

import streamlit as st
import requests
import json
import pandas as pd
from typing import Dict, List, Optional, Any, Tuple
import time
import re
from datetime import datetime, timedelta
import os
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv()

class ResearchAgent:
    """
    Agente de investigaci√≥n para buscar informaci√≥n externa y generar insights
    """
    
    def __init__(self):
        self.api_keys = {
            'google': os.getenv('GOOGLE_SEARCH_API_KEY'),
            'bing': os.getenv('BING_SEARCH_API_KEY'),
            'wikipedia': None,  # Wikipedia no requiere API key
            'news': os.getenv('NEWS_API_KEY')
        }
        
        self.search_engines = ['wikipedia', 'google', 'bing', 'news']
        self.research_cache = {}
        self.max_cache_age = 3600  # 1 hora en segundos
        
    def research_topic(self, topic: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Investigar un tema espec√≠fico relacionado con los datos
        
        Args:
            topic: Tema a investigar
            context: Contexto de los datos actuales
            
        Returns:
            Dict: Resultados de la investigaci√≥n
        """
        # Verificar cache primero
        cache_key = f"{topic}_{hash(str(context))}"
        if self._is_cached(cache_key):
            return self.research_cache[cache_key]
        
        st.info(f"üîç Investigando: {topic}")
        
        research_results = {
            'topic': topic,
            'timestamp': datetime.now().isoformat(),
            'sources': [],
            'insights': [],
            'recommendations': [],
            'confidence': 0.0
        }
        
        try:
            # 1. B√∫squeda en Wikipedia para contexto general
            wikipedia_info = self._search_wikipedia(topic)
            if wikipedia_info:
                research_results['sources'].append(wikipedia_info)
            
            # 2. B√∫squeda web para informaci√≥n actual
            web_results = self._search_web(topic, context)
            if web_results:
                research_results['sources'].extend(web_results)
            
            # 3. B√∫squeda de noticias para informaci√≥n reciente
            news_results = self._search_news(topic)
            if news_results:
                research_results['sources'].extend(news_results)
            
            # 4. Analizar contexto de datos si est√° disponible
            if context:
                data_insights = self._analyze_data_context(topic, context)
                if data_insights:
                    research_results['insights'].extend(data_insights)
            
            # 5. Generar insights basados en la investigaci√≥n
            insights = self._generate_insights(topic, research_results['sources'])
            research_results['insights'].extend(insights)
            
            # 6. Generar recomendaciones
            recommendations = self._generate_recommendations(topic, research_results)
            research_results['recommendations'].extend(recommendations)
            
            # 7. Calcular confianza en los resultados
            research_results['confidence'] = self._calculate_confidence(research_results)
            
            # Guardar en cache
            self.research_cache[cache_key] = research_results
            
            return research_results
            
        except Exception as e:
            st.error(f"‚ùå Error en investigaci√≥n: {str(e)}")
            return research_results
    
    def _search_wikipedia(self, topic: str) -> Optional[Dict[str, Any]]:
        """
        Buscar informaci√≥n en Wikipedia
        
        Args:
            topic: Tema a buscar
            
        Returns:
            Dict: Informaci√≥n de Wikipedia
        """
        try:
            # Buscar p√°gina de Wikipedia
            search_url = "https://es.wikipedia.org/api/rest_v1/page/summary/" + topic.replace(" ", "_")
            response = requests.get(search_url, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                return {
                    'source': 'Wikipedia',
                    'title': data.get('title', ''),
                    'extract': data.get('extract', ''),
                    'url': data.get('content_urls', {}).get('desktop', {}).get('page', ''),
                    'relevance_score': self._calculate_relevance_score(topic, data.get('extract', ''))
                }
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Error buscando en Wikipedia: {str(e)}")
        
        return None
    
    def _search_web(self, topic: str, context: Dict[str, Any] = None) -> List[Dict[str, Any]]:
        """
        Buscar informaci√≥n en la web usando Google Custom Search
        
        Args:
            topic: Tema a buscar
            context: Contexto de los datos
            
        Returns:
            List[Dict]: Resultados de b√∫squeda web
        """
        results = []
        
        if not self.api_keys['google']:
            st.warning("‚ö†Ô∏è Google Search API key no configurada")
            return results
        
        try:
            # Construir query de b√∫squeda
            query = self._build_search_query(topic, context)
            
            # Buscar en Google
            search_url = "https://www.googleapis.com/customsearch/v1"
            params = {
                'key': self.api_keys['google'],
                'cx': os.getenv('GOOGLE_SEARCH_ENGINE_ID', ''),
                'q': query,
                'num': 5,
                'lr': 'lang_es'  # B√∫squeda en espa√±ol
            }
            
            response = requests.get(search_url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                for item in data.get('items', []):
                    results.append({
                        'source': 'Google Search',
                        'title': item.get('title', ''),
                        'snippet': item.get('snippet', ''),
                        'url': item.get('link', ''),
                        'relevance_score': self._calculate_relevance_score(topic, item.get('snippet', ''))
                    })
        
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Error en b√∫squeda web: {str(e)}")
        
        return results
    
    def _search_news(self, topic: str) -> List[Dict[str, Any]]:
        """
        Buscar noticias recientes sobre el tema
        
        Args:
            topic: Tema a buscar
            
        Returns:
            List[Dict]: Resultados de noticias
        """
        results = []
        
        if not self.api_keys['news']:
            return results
        
        try:
            # Buscar noticias de los √∫ltimos 30 d√≠as
            from_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
            
            news_url = "https://newsapi.org/v2/everything"
            params = {
                'apiKey': self.api_keys['news'],
                'q': topic,
                'from': from_date,
                'language': 'es',
                'sortBy': 'relevancy',
                'pageSize': 5
            }
            
            response = requests.get(news_url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                for article in data.get('articles', []):
                    results.append({
                        'source': 'News API',
                        'title': article.get('title', ''),
                        'description': article.get('description', ''),
                        'url': article.get('url', ''),
                        'published_at': article.get('publishedAt', ''),
                        'relevance_score': self._calculate_relevance_score(topic, article.get('description', ''))
                    })
        
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Error buscando noticias: {str(e)}")
        
        return results
    
    def _analyze_data_context(self, topic: str, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Analizar el contexto de los datos para generar insights
        
        Args:
            topic: Tema a analizar
            context: Contexto de los datos
            
        Returns:
            List[Dict]: Insights basados en datos
        """
        insights = []
        
        try:
            # Analizar datos de pasajeros
            if 'passengers' in context and context['passengers']:
                passenger_insights = self._analyze_passenger_context(topic, context['passengers'])
                insights.extend(passenger_insights)
            
            # Analizar datos de feriados
            if 'holidays' in context and context['holidays']:
                holiday_insights = self._analyze_holiday_context(topic, context['holidays'])
                insights.extend(holiday_insights)
            
            # Analizar filtros aplicados
            if 'filters' in context and context['filters']:
                filter_insights = self._analyze_filter_context(topic, context['filters'])
                insights.extend(filter_insights)
        
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Error analizando contexto: {str(e)}")
        
        return insights
    
    def _analyze_passenger_context(self, topic: str, passenger_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Analizar contexto de datos de pasajeros
        
        Args:
            topic: Tema a analizar
            passenger_data: Datos de pasajeros
            
        Returns:
            List[Dict]: Insights de pasajeros
        """
        insights = []
        
        try:
            # Extraer palabras clave del tema
            topic_keywords = self._extract_keywords(topic)
            
            # Analizar patrones estacionales
            if any(keyword in topic_keywords for keyword in ['estacional', 'temporada', 'mes', 'a√±o']):
                insights.append({
                    'type': 'seasonal_analysis',
                    'description': 'An√°lisis de patrones estacionales en datos de pasajeros',
                    'confidence': 0.8,
                    'data_points': passenger_data.get('total_records', 0)
                })
            
            # Analizar crecimiento
            if any(keyword in topic_keywords for keyword in ['crecimiento', 'tendencia', 'evoluci√≥n']):
                insights.append({
                    'type': 'growth_analysis',
                    'description': 'An√°lisis de tendencias de crecimiento en tr√°fico a√©reo',
                    'confidence': 0.7,
                    'data_points': passenger_data.get('total_records', 0)
                })
            
            # Analizar impacto de feriados
            if any(keyword in topic_keywords for keyword in ['feriado', 'vacaciones', 'impacto']):
                insights.append({
                    'type': 'holiday_impact',
                    'description': 'An√°lisis del impacto de feriados en el tr√°fico a√©reo',
                    'confidence': 0.9,
                    'data_points': passenger_data.get('total_records', 0)
                })
        
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Error analizando contexto de pasajeros: {str(e)}")
        
        return insights
    
    def _analyze_holiday_context(self, topic: str, holiday_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Analizar contexto de datos de feriados
        
        Args:
            topic: Tema a analizar
            holiday_data: Datos de feriados
            
        Returns:
            List[Dict]: Insights de feriados
        """
        insights = []
        
        try:
            topic_keywords = self._extract_keywords(topic)
            
            # Analizar tipos de feriados
            if any(keyword in topic_keywords for keyword in ['tipo', 'categor√≠a', 'p√∫blico', 'religioso']):
                insights.append({
                    'type': 'holiday_type_analysis',
                    'description': 'An√°lisis de tipos y categor√≠as de feriados',
                    'confidence': 0.8,
                    'data_points': holiday_data.get('total_records', 0)
                })
            
            # Analizar distribuci√≥n geogr√°fica
            if any(keyword in topic_keywords for keyword in ['pa√≠s', 'regi√≥n', 'geogr√°fico']):
                insights.append({
                    'type': 'geographic_analysis',
                    'description': 'An√°lisis de distribuci√≥n geogr√°fica de feriados',
                    'confidence': 0.7,
                    'data_points': holiday_data.get('countries', 0)
                })
        
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Error analizando contexto de feriados: {str(e)}")
        
        return insights
    
    def _analyze_filter_context(self, topic: str, filters: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Analizar contexto de filtros aplicados
        
        Args:
            topic: Tema a analizar
            filters: Filtros aplicados
            
        Returns:
            List[Dict]: Insights de filtros
        """
        insights = []
        
        try:
            # Analizar filtros temporales
            if 'year_range' in filters:
                year_min, year_max = filters['year_range']
                insights.append({
                    'type': 'temporal_filter',
                    'description': f'An√°lisis limitado al per√≠odo {year_min}-{year_max}',
                    'confidence': 0.9,
                    'data_points': f"{year_max - year_min + 1} a√±os"
                })
            
            # Analizar filtros geogr√°ficos
            if 'countries' in filters and filters['countries']:
                country_count = len(filters['countries'])
                insights.append({
                    'type': 'geographic_filter',
                    'description': f'An√°lisis limitado a {country_count} pa√≠ses espec√≠ficos',
                    'confidence': 0.9,
                    'data_points': country_count
                })
        
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Error analizando contexto de filtros: {str(e)}")
        
        return insights
    
    def _generate_insights(self, topic: str, sources: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Generar insights basados en la investigaci√≥n
        
        Args:
            topic: Tema investigado
            sources: Fuentes de informaci√≥n
            
        Returns:
            List[Dict]: Insights generados
        """
        insights = []
        
        try:
            # Combinar informaci√≥n de todas las fuentes
            combined_text = ""
            for source in sources:
                combined_text += f"{source.get('title', '')} {source.get('snippet', '')} {source.get('extract', '')} "
            
            # Generar insights basados en el contenido
            if 'patr√≥n' in topic.lower() or 'tendencia' in topic.lower():
                insights.append({
                    'type': 'pattern_insight',
                    'description': 'Identificaci√≥n de patrones en datos de tr√°fico a√©reo',
                    'confidence': 0.8,
                    'source': 'research_analysis'
                })
            
            if 'feriado' in topic.lower() or 'vacaciones' in topic.lower():
                insights.append({
                    'type': 'holiday_insight',
                    'description': 'Impacto de feriados en el comportamiento de viajes',
                    'confidence': 0.9,
                    'source': 'research_analysis'
                })
            
            if 'crecimiento' in topic.lower() or 'evoluci√≥n' in topic.lower():
                insights.append({
                    'type': 'growth_insight',
                    'description': 'Tendencias de crecimiento en el sector a√©reo',
                    'confidence': 0.7,
                    'source': 'research_analysis'
                })
        
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Error generando insights: {str(e)}")
        
        return insights
    
    def _generate_recommendations(self, topic: str, research_results: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Generar recomendaciones basadas en la investigaci√≥n
        
        Args:
            topic: Tema investigado
            research_results: Resultados de la investigaci√≥n
            
        Returns:
            List[Dict]: Recomendaciones generadas
        """
        recommendations = []
        
        try:
            # Recomendaciones basadas en el tema
            if 'an√°lisis' in topic.lower():
                recommendations.append({
                    'type': 'analysis_recommendation',
                    'description': 'Considerar aplicar filtros espec√≠ficos para un an√°lisis m√°s detallado',
                    'priority': 'medium'
                })
            
            if 'predicci√≥n' in topic.lower() or 'pron√≥stico' in topic.lower():
                recommendations.append({
                    'type': 'prediction_recommendation',
                    'description': 'Usar datos hist√≥ricos para generar proyecciones futuras',
                    'priority': 'high'
                })
            
            if 'comparaci√≥n' in topic.lower():
                recommendations.append({
                    'type': 'comparison_recommendation',
                    'description': 'Comparar diferentes pa√≠ses o per√≠odos para identificar diferencias',
                    'priority': 'medium'
                })
            
            # Recomendaciones basadas en la confianza
            if research_results['confidence'] < 0.5:
                recommendations.append({
                    'type': 'data_quality_recommendation',
                    'description': 'Considerar validar los datos con fuentes adicionales',
                    'priority': 'high'
                })
        
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Error generando recomendaciones: {str(e)}")
        
        return recommendations
    
    def _build_search_query(self, topic: str, context: Dict[str, Any] = None) -> str:
        """
        Construir query de b√∫squeda optimizada
        
        Args:
            topic: Tema a buscar
            context: Contexto de los datos
            
        Returns:
            str: Query de b√∫squeda optimizada
        """
        query = topic
        
        # Agregar t√©rminos relacionados con aviaci√≥n si no est√°n presentes
        aviation_terms = ['aviaci√≥n', 'a√©reo', 'aerol√≠neas', 'pasajeros', 'tr√°fico a√©reo']
        if not any(term in topic.lower() for term in aviation_terms):
            query += " aviaci√≥n tr√°fico a√©reo"
        
        # Agregar contexto temporal si est√° disponible
        if context and 'filters' in context:
            filters = context['filters']
            if 'year_range' in filters:
                year_min, year_max = filters['year_range']
                query += f" {year_min}-{year_max}"
        
        return query
    
    def _extract_keywords(self, text: str) -> List[str]:
        """
        Extraer palabras clave de un texto
        
        Args:
            text: Texto a procesar
            
        Returns:
            List[str]: Palabras clave extra√≠das
        """
        # Palabras clave relevantes para el an√°lisis de datos
        keywords = []
        
        # T√©rminos temporales
        temporal_terms = ['estacional', 'temporada', 'mes', 'a√±o', 'crecimiento', 'tendencia', 'evoluci√≥n']
        for term in temporal_terms:
            if term in text.lower():
                keywords.append(term)
        
        # T√©rminos de an√°lisis
        analysis_terms = ['patr√≥n', 'an√°lisis', 'comparaci√≥n', 'predicci√≥n', 'pron√≥stico']
        for term in analysis_terms:
            if term in text.lower():
                keywords.append(term)
        
        # T√©rminos de feriados
        holiday_terms = ['feriado', 'vacaciones', 'impacto', 'p√∫blico', 'religioso']
        for term in holiday_terms:
            if term in text.lower():
                keywords.append(term)
        
        return keywords
    
    def _calculate_relevance_score(self, topic: str, content: str) -> float:
        """
        Calcular score de relevancia entre un tema y contenido
        
        Args:
            topic: Tema de b√∫squeda
            content: Contenido a evaluar
            
        Returns:
            float: Score de relevancia (0-1)
        """
        if not content:
            return 0.0
        
        topic_words = set(topic.lower().split())
        content_words = set(content.lower().split())
        
        # Calcular intersecci√≥n de palabras
        common_words = topic_words.intersection(content_words)
        
        if not topic_words:
            return 0.0
        
        # Score basado en la proporci√≥n de palabras comunes
        relevance_score = len(common_words) / len(topic_words)
        
        # Bonus por palabras clave importantes
        important_words = ['aviaci√≥n', 'a√©reo', 'pasajeros', 'feriado', 'tr√°fico']
        for word in important_words:
            if word in content.lower():
                relevance_score += 0.1
        
        return min(relevance_score, 1.0)
    
    def _calculate_confidence(self, research_results: Dict[str, Any]) -> float:
        """
        Calcular confianza en los resultados de investigaci√≥n
        
        Args:
            research_results: Resultados de la investigaci√≥n
            
        Returns:
            float: Score de confianza (0-1)
        """
        confidence = 0.0
        
        # Confianza basada en n√∫mero de fuentes
        source_count = len(research_results.get('sources', []))
        if source_count > 0:
            confidence += min(source_count * 0.2, 0.6)
        
        # Confianza basada en relevancia de fuentes
        sources = research_results.get('sources', [])
        if sources:
            avg_relevance = sum(source.get('relevance_score', 0) for source in sources) / len(sources)
            confidence += avg_relevance * 0.3
        
        # Confianza basada en insights generados
        insights_count = len(research_results.get('insights', []))
        if insights_count > 0:
            confidence += min(insights_count * 0.1, 0.2)
        
        return min(confidence, 1.0)
    
    def _is_cached(self, cache_key: str) -> bool:
        """
        Verificar si un resultado est√° en cache
        
        Args:
            cache_key: Clave del cache
            
        Returns:
            bool: True si est√° en cache y es v√°lido
        """
        if cache_key not in self.research_cache:
            return False
        
        cached_result = self.research_cache[cache_key]
        timestamp = datetime.fromisoformat(cached_result['timestamp'])
        
        # Verificar si el cache no ha expirado
        return (datetime.now() - timestamp).seconds < self.max_cache_age
    
    def get_research_summary(self, research_results: Dict[str, Any]) -> str:
        """
        Generar resumen de la investigaci√≥n
        
        Args:
            research_results: Resultados de la investigaci√≥n
            
        Returns:
            str: Resumen formateado
        """
        if not research_results:
            return "No hay resultados de investigaci√≥n disponibles."
        
        summary = f"## üîç Investigaci√≥n: {research_results['topic']}\n\n"
        
        # Resumen de fuentes
        sources = research_results.get('sources', [])
        if sources:
            summary += f"**üìö Fuentes encontradas:** {len(sources)}\n"
            for source in sources[:3]:  # Mostrar solo las primeras 3
                summary += f"- {source.get('source', 'Fuente desconocida')}: {source.get('title', 'Sin t√≠tulo')}\n"
            summary += "\n"
        
        # Resumen de insights
        insights = research_results.get('insights', [])
        if insights:
            summary += f"**üí° Insights generados:** {len(insights)}\n"
            for insight in insights[:3]:  # Mostrar solo los primeros 3
                summary += f"- {insight.get('description', 'Sin descripci√≥n')}\n"
            summary += "\n"
        
        # Resumen de recomendaciones
        recommendations = research_results.get('recommendations', [])
        if recommendations:
            summary += f"**üéØ Recomendaciones:** {len(recommendations)}\n"
            for rec in recommendations[:3]:  # Mostrar solo las primeras 3
                summary += f"- {rec.get('description', 'Sin descripci√≥n')}\n"
            summary += "\n"
        
        # Confianza
        confidence = research_results.get('confidence', 0)
        summary += f"**üìä Confianza:** {confidence:.1%}\n"
        
        return summary

